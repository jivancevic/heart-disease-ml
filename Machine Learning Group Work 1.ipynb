{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df83d65",
   "metadata": {},
   "source": [
    "This is the project for Machine Learning at UA. \n",
    "First, we import the datasets into the notebook after we downloaded the files from the website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e5d5b",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# read csv files\n",
    "cleveland_df   = pd.read_csv(\"processed.cleveland.data\", header=None, na_values =[\"?\", -9.0])\n",
    "switzerland_df = pd.read_csv(\"processed.switzerland.data\", header=None, na_values =[\"?\", -9.0])\n",
    "va_df          = pd.read_csv(\"processed.va.data\", header=None, na_values =[\"?\", -9.0])\n",
    "hungarian_df   = pd.read_csv(\"processed.hungarian.data\", header=None, na_values =[\"?\", -9.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65794d",
   "metadata": {},
   "source": [
    "Now we need to organize the data and add headers to the data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column to keep track of the source of the data\n",
    "cleveland_df[\"Source\"] = \"cleveland\"\n",
    "switzerland_df[\"Source\"] = \"switzerland\"\n",
    "va_df[\"Source\"] = \"va\"\n",
    "hungarian_df[\"Source\"] = \"hungarian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add headers to the data frames\n",
    "headers = {0 : \"age\",\n",
    "               1 : \"sex\",\n",
    "               2 : \"cp\",\n",
    "               3 : \"trestbps\",\n",
    "               4 : \"chol\",\n",
    "               5 : \"fbs\",\n",
    "               6 : \"restecg\",\n",
    "               7 : \"thalach\",\n",
    "               8 : \"exang\",\n",
    "               9 : \"oldpeak\",\n",
    "               10 : \"slope\",\n",
    "               11 : \"ca\",\n",
    "               12 : \"thal\",\n",
    "               13 : \"diagnosis\"}\n",
    "\n",
    "cleveland_df = cleveland_df.rename(columns=headers)\n",
    "switzerland_df = switzerland_df.rename(columns=headers)\n",
    "va_df = va_df.rename(columns=headers)\n",
    "hungarian_df = hungarian_df.rename(columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62c848",
   "metadata": {},
   "source": [
    "Now we want to combine the different datasets from Cleveland, Switzerland, Va and Hungary into one big dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df = pd.concat([cleveland_df, switzerland_df, va_df, hungarian_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df['Source']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0df4aa",
   "metadata": {},
   "source": [
    "Next, we want to look at some details of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475ba4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(heart_disease_df.head())\n",
    "print(heart_disease_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21f9c2",
   "metadata": {},
   "source": [
    "Next, let's use the command from the lecture to describe the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e38880",
   "metadata": {},
   "source": [
    "Let's collect some more information concerning the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ae86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heart_disease_df.shape)\n",
    "print(heart_disease_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76372ce2",
   "metadata": {},
   "source": [
    "Some more analytics. There are 920 observations with 15 14 features each, resulting in one diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39807cd6",
   "metadata": {},
   "source": [
    "Analyse the Pearson correlation coefficient, to find connections within the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(heart_disease_df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004b15e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rs.rand(10, 10))\n",
    "corr = heart_disease_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7292f",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "heart_disease_df.hist(figsize=(10,10))\n",
    "plt.show()\n",
    "plt.savefig('heart_disease_hist.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ce741",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.head()\n",
    "sns.set_style('whitegrid')\n",
    "sns.histplot(heart_disease_df['diagnosis'], kde = False, color ='red', bins = 30)\n",
    "plt.savefig('diagnosis_distribution.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2837ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rs.rand(9, 9))\n",
    "corr = heart_disease_df.corr().round(3) # round to 3 decimal places\n",
    "# Format the correlation matrix to display only the last 3 numbers\n",
    "corr_style = corr.style.format(\"{:.3f}\")\n",
    "\n",
    "# Apply a color map to the correlation matrix\n",
    "corr_heatmap = corr_style.background_gradient(cmap='coolwarm')\n",
    "corr_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca625294",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = heart_disease_df.corr()\n",
    "\n",
    "corr_matrix.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "nmbr_features = 10\n",
    "\n",
    "top_correlations = corr_matrix['diagnosis'].abs().sort_values(ascending=False)[1:nmbr_features+1]\n",
    "print(top_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(heart_disease_df,'heart_disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2db33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots_just_one(df1):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "    df1 = (df1 - df1.mean()) / df1.std()\n",
    "\n",
    "    # plot boxplot of the first DataFrame\n",
    "    bp1 = df1.boxplot(ax=ax, color='blue')\n",
    "\n",
    "    # set labels and title\n",
    "    ax.set_xlabel('Variables')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title('Boxplot of all variables')\n",
    "\n",
    "    # create a legend\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplots_just_one(heart_disease_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=heart_disease_df, hue='diagnosis', vars=['age'], ax=axes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df['ca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the age ranges for grouping\n",
    "age_bins = [20, 30, 40, 50, 60, 70, 80]\n",
    "\n",
    "# Create a new column 'age_group' based on age bins\n",
    "heart_disease_df['age_group'] = pd.cut(heart_disease_df['age'], bins=age_bins)\n",
    "\n",
    "# Create the boxplot with age group on x-axis and diagnosis on y-axis\n",
    "sns.boxplot(x='age_group', y='diagnosis', data=heart_disease_df)\n",
    "heart_disease_df= heart_disease_df.drop('age_group', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f35937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by age and calculate the mean, median of a column for each group\n",
    "# age_stats_df = heart_disease_df.groupby('age')['diagnosis'].agg(['mean', 'median']).reset_index()\n",
    "\n",
    "# Plot the graph using seaborn lineplot\n",
    "# sns.lineplot(x='age', y='mean', data=age_stats_df, label='Average')\n",
    "#sns.lineplot(x='age', y='median', data=age_stats_df, label='Median')\n",
    "#sns.lineplot(x='age', y='diagnosis', data=heart_disease_df, estimator=None, alpha=0.2, color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbabb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(x='ca',y='diagnosis',data=heart_disease_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc097a14",
   "metadata": {},
   "source": [
    "## Plots for IEEE-Paper\n",
    "\n",
    "### Only Cleveland Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd67bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "cleveland_df.hist(figsize=(10,10))\n",
    "plt.savefig('heart_disease_hist.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6700b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 2)) # Create a new figure with size (8, 2)\n",
    "sns.set_style('whitegrid')\n",
    "sns.histplot(cleveland_df['diagnosis'], kde=False, color='red', bins=30, ax=ax) # Add the plot to the specified axis\n",
    "plt.savefig('diagnosis_distribution.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rs.rand(9, 9))\n",
    "corr = cleveland_df.corr().round(3)\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rs.rand(9, 9))\n",
    "corr = cleveland_df.corr().round(3) # round to 3 decimal places\n",
    "# Format the correlation matrix to display only the last 3 numbers\n",
    "corr_style = corr.style.format(\"{:.3f}\")\n",
    "\n",
    "# Apply a color map to the correlation matrix\n",
    "corr_heatmap = corr_style.background_gradient(cmap='coolwarm')\n",
    "corr_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = cleveland_df.corr()\n",
    "\n",
    "corr_matrix.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "nmbr_features = 10\n",
    "\n",
    "top_correlations = corr_matrix['diagnosis'].abs().sort_values(ascending=False)[1:nmbr_features+1]\n",
    "print(top_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9643b75",
   "metadata": {},
   "source": [
    "## Function for visualizing dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2f3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_data(df, name):\n",
    "    \n",
    "    df.describe()\n",
    "\n",
    "    sns.set()\n",
    "    df.hist(figsize=(10,10))\n",
    "    plt.savefig(name+'_hist.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 2)) # Create a new figure with size (8, 2)\n",
    "    sns.set_style('whitegrid')\n",
    "    diagnosis = df['diagnosis'].apply(lambda x: 1 if x > 1 else x) # Replace values greater than 1 with 1    \n",
    "    sns.histplot(diagnosis, kde=False, color='red', bins=30, ax=ax) # Add the plot to the specified axis\n",
    "    plt.savefig(name+'_diagnosis_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    corr_matrix = df.corr()\n",
    "    corr_matrix.style.background_gradient(cmap='coolwarm')\n",
    "    nmbr_features = 5\n",
    "    top_correlations = corr_matrix['diagnosis'].abs().sort_values(ascending=False)[1:nmbr_features+1]\n",
    "    print(top_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(df, name, df2=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    sns.set()\n",
    "    df.hist(ax=ax, alpha=0.5, color='blue', label='df1', bins=30)\n",
    "    if df2 is not None:\n",
    "        df2.hist(ax=ax, alpha=0.5, color='green', label='df2', bins=30)\n",
    "    ax.legend()\n",
    "    plt.savefig(name+'_hist.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 2)) # Create a new figure with size (8, 2)\n",
    "    sns.set_style('whitegrid')\n",
    "    diagnosis = df['diagnosis'].apply(lambda x: 1 if x > 1 else x) # Replace values greater than 1 with 1    \n",
    "    sns.histplot(diagnosis, kde=False, color='red', bins=30, ax=ax) # Add the plot to the specified axis\n",
    "    plt.savefig(name+'_diagnosis_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    corr_matrix = df.corr()\n",
    "    corr_matrix.style.background_gradient(cmap='coolwarm')\n",
    "    nmbr_features = 5\n",
    "    top_correlations = corr_matrix['diagnosis'].abs().sort_values(ascending=False)[1:nmbr_features+1]\n",
    "    print(top_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7839a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(hungarian_df, 'hungarian', cleveland_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceed212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_data(va_df,'va')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(switzerland_df,'switzerland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(cleveland_df, 'cleveland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "cleveland_df.boxplot(ax=ax)\n",
    "\n",
    "# set labels and title\n",
    "ax.set_xlabel('Variables')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Boxplot of all variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ac2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(df1, df2):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "    df1 = (df1 - df1.mean()) / df1.std()\n",
    "    df2 = (df2 - df2.mean()) / df2.std()\n",
    "\n",
    "    # plot boxplot of the first DataFrame\n",
    "    bp1 = df1.boxplot(ax=ax, color='blue')\n",
    "\n",
    "    # plot boxplot of the second DataFrame\n",
    "    bp2 = df2.boxplot(ax=ax, color='red')\n",
    "\n",
    "    # set labels and title\n",
    "    ax.set_xlabel('Variables')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title('Boxplot of all variables')\n",
    "\n",
    "    # create a legend\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff50e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplots(cleveland_df, hungarian_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplots(cleveland_df, switzerland_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c469f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "switzerland_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "hungarian_df.boxplot(ax=ax)\n",
    "\n",
    "# set labels and title\n",
    "ax.set_xlabel('Variables')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Boxplot of all variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access first row\n",
    "desc = cleveland_df.describe()\n",
    "\n",
    "row1 = desc.iloc[0]\n",
    "row2 = desc.iloc[1]\n",
    "row3 = desc.iloc[2]\n",
    "\n",
    "print(row1)\n",
    "print(row2)\n",
    "print(row3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08db8ee",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "83676f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUOUS_FACTORS = [\"age\", \"chol\", \"oldpeak\", \"thalach\", \"trestbps\"]\n",
    "DISCRETE_FACTORS = [\"ca\", \"cp\", \"exang\", \"fbs\", \"restecg\", \"sex\", \"slope\", \"thal\"]\n",
    "TARGET = [\"diagnosis\"]\n",
    "\n",
    "def pipeline(df):\n",
    "    Y = df[\"diagnosis\"].copy()\n",
    "    X = df.drop(\"diagnosis\", axis=1)\n",
    "    \n",
    "    # Handle the discrete and continuous variables seperatly\n",
    "    X_continuous = X[CONTINUOUS_FACTORS]\n",
    "    X_discrete = X[DISCRETE_FACTORS].fillna(value=5) #For all the discrete values, replace missing values with 5\n",
    "    \n",
    "     # For continuous variables, replace missing values with the median and then normalize by subtracting the mean and dividing by the standard deviation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "    continuous_Pipeline = sklearn.pipeline.Pipeline( [(\"imputer\", sklearn.impute.SimpleImputer(strategy=\"median\")),\n",
    "                                             (\"scaler\", sklearn.preprocessing.StandardScaler())\n",
    "                                            ]\n",
    "                                           )\n",
    "    X_continuous_scaled = continuous_Pipeline.fit_transform(X_continuous)\n",
    "    \n",
    "    # for discrete variables, one-hot encode the data\n",
    "    discrete_Pipeline = sklearn.pipeline.Pipeline( [(\"one_hot\", sklearn.preprocessing.OneHotEncoder(handle_unknown ='ignore'))\n",
    "                                            ]\n",
    "                                           )\n",
    "    X_discrete_one_hot = discrete_Pipeline.fit_transform(X_discrete)\n",
    "    \n",
    "    X_fully_preprocessed = np.concatenate((X_continuous_scaled, X_discrete_one_hot.toarray()), axis = 1)\n",
    "    \n",
    "    Y_binary = (Y>0) # True if they have heart disease, False otherwide\n",
    "    \n",
    "    return X_fully_preprocessed, Y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = pipeline(heart_disease_df)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "groups = heart_disease_df.groupby('Source').groups\n",
    "for source, indices in groups.items():\n",
    "    print(f\"{source}: {indices}\")    \n",
    "\n",
    "    \n",
    "X_cl = X[0:303, :]\n",
    "Y_cl = Y[0:303]\n",
    "\n",
    "X_hg = X[304:598, :]\n",
    "Y_hg = Y[304:598]\n",
    "\n",
    "X_switzerland = X[599:722, :]\n",
    "Y_switzerland = Y[599:722]\n",
    "\n",
    "X_va = X[723:920, :]\n",
    "Y_va = Y[723:920]\n",
    "\n",
    "print(va_df.shape)\n",
    "print(X_va.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUOUS_FACTORS = [\"age\", \"chol\", \"oldpeak\", \"thalach\", \"trestbps\"]\n",
    "DISCRETE_FACTORS = [\"ca\", \"cp\", \"exang\", \"fbs\", \"restecg\", \"sex\", \"slope\", \"thal\"]\n",
    "TARGET = [\"diagnosis\"]\n",
    "\n",
    "# training data - Cleveland data\n",
    "trainY = cleveland_df[\"diagnosis\"].copy()\n",
    "trainX = cleveland_df.drop(\"diagnosis\", axis=1)\n",
    "\n",
    "# testing data - Hungary, Va, Switzerland\n",
    "testY_hg = hungarian_df[\"diagnosis\"].copy()\n",
    "testX_hg = hungarian_df.drop(\"diagnosis\", axis=1)\n",
    "\n",
    "testY_va = va_df[\"diagnosis\"].copy()\n",
    "testX_va = va_df.drop(\"diagnosis\", axis=1)\n",
    "\n",
    "testY_sw = switzerland_df[\"diagnosis\"].copy()\n",
    "testX_sw = switzerland_df.drop(\"diagnosis\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eaf3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline(dfX,dfY)\n",
    "    # Handle the discrete and continuous variables seperatly\n",
    "    trainX_continuous = trainX[CONTINUOUS_FACTORS]\n",
    "    trainX_discrete = trainX[DISCRETE_FACTORS].fillna(value=5) #For all the discrete values, replace missing values with 5\n",
    "\n",
    "\n",
    "    # For continuous variables, replace missing values with the median and then normalize by subtracting the mean and dividing by the standard deviation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "    continuous_Pipeline = sklearn.pipeline.Pipeline( [(\"imputer\", sklearn.impute.SimpleImputer(strategy=\"median\")),\n",
    "                                             (\"scaler\", sklearn.preprocessing.StandardScaler())\n",
    "                                            ]\n",
    "                                           )\n",
    "    trainX_continuous_scaled = continuous_Pipeline.fit_transform(trainX_continuous)\n",
    "    \n",
    "    \n",
    "    # for discrete variables, one-hot encode the data\n",
    "    discrete_Pipeline = sklearn.pipeline.Pipeline( [(\"one_hot\", sklearn.preprocessing.OneHotEncoder(handle_unknown ='ignore'))\n",
    "                                            ]\n",
    "                                           )\n",
    "    trainX_discrete_one_hot = discrete_Pipeline.fit_transform(trainX_discrete)\n",
    "\n",
    "    trainX_fully_preprocessed = np.concatenate((trainX_continuous_scaled, trainX_discrete_one_hot.toarray()), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ec8f4",
=======
   "id": "76ec3402",
>>>>>>> a32b32ffa287ab4092b671d6d4b8d54d45a2a16a
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUOUS_FACTORS = [\"age\", \"chol\", \"oldpeak\", \"thalach\", \"trestbps\"]\n",
    "DISCRETE_FACTORS = [\"ca\", \"cp\", \"exang\", \"fbs\", \"restecg\", \"sex\", \"slope\", \"thal\"]\n",
    "TARGET = [\"diagnosis\"]\n",
    "\n",
    "def pipeline(df):\n",
    "    Y = df[TARGET + [\"Source\"]].copy()\n",
    "    X = df[CONTINUOUS_FACTORS + DISCRETE_FACTORS + [\"Source\"]].copy()\n",
    "    \n",
    "    # Handle the discrete and continuous variables seperatly\n",
    "    X_continuous = X[CONTINUOUS_FACTORS]\n",
    "    X_discrete = X[DISCRETE_FACTORS].fillna(value=5) #For all the discrete values, replace missing values with 5\n",
    "    \n",
    "     # For continuous variables, replace missing values with the median and then normalize by subtracting the mean and dividing by the standard deviation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "    continuous_Pipeline = sklearn.pipeline.Pipeline( [(\"imputer\", sklearn.impute.SimpleImputer(strategy=\"median\")),\n",
    "                                             (\"scaler\", sklearn.preprocessing.StandardScaler())\n",
    "                                            ]\n",
    "                                           )\n",
    "    X_continuous_scaled = continuous_Pipeline.fit_transform(X_continuous)\n",
    "    \n",
    "    # for discrete variables, one-hot encode the data\n",
    "    discrete_Pipeline = sklearn.pipeline.Pipeline( [(\"one_hot\", sklearn.preprocessing.OneHotEncoder(handle_unknown ='ignore'))\n",
    "                                            ]\n",
    "                                           )\n",
    "    X_discrete_one_hot = discrete_Pipeline.fit_transform(X_discrete)\n",
    "    \n",
    "    X_fully_preprocessed = np.concatenate((X_continuous_scaled, X_discrete_one_hot.toarray()), axis = 1)\n",
    "    X_fully_preprocessed = np.hstack((X_fully_preprocessed, X[[\"Source\"]].values))\n",
    "\n",
    "    # Create a binary target variable indicating presence or absence of heart disease and add \"Source\" column\n",
    "    Y_binary = Y.copy()\n",
    "    Y_binary[\"diagnosis\"] = (Y_binary[\"diagnosis\"] > 0).astype(int) # Convert diagnosis to binary values\n",
    "\n",
    "    return X_fully_preprocessed, Y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f972ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = pipeline(heart_disease_df)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(type(X))\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset(X, Y, dataset_name):\n",
    "    X_dataset = X[X[:, -1] == dataset_name]\n",
    "    X_dataset = X_dataset[:, :-1]\n",
    "    Y_dataset = Y.copy()\n",
    "    Y_dataset = Y_dataset[Y_dataset[\"Source\"] == dataset_name]\n",
    "    Y_dataset = Y_dataset.drop(\"Source\", axis=1)\n",
    "    return X_dataset, Y_dataset.values\n",
    "\n",
    "def drop_source(X, Y):\n",
    "    X = X[:, :-1]\n",
    "    Y = Y.drop(\"Source\", axis=1)\n",
    "    return X, Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleveland, Y_cleveland = extract_dataset(X, Y, \"cleveland\")\n",
    "X_switzerland, Y_switzerland = extract_dataset(X, Y, \"switzerland\")\n",
    "X_va, Y_va = extract_dataset(X, Y, \"va\")\n",
    "X_hungarian, Y_hungarian = extract_dataset(X, Y, \"hungarian\")\n",
    "X, Y = drop_source(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea46dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_cleveland.shape, Y_cleveland.shape)\n",
    "print(X_switzerland.shape, Y_switzerland.shape)\n",
    "print(X_va.shape, Y_va.shape)\n",
    "print(X_hungarian.shape, Y_hungarian.shape)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96375a09",
   "metadata": {},
   "source": [
    "Preprocessing done. There are two datasets: trainY_binary and trainY. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80798f02",
   "metadata": {},
   "source": [
    "# Train models for full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f5d95",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea216a0a",
   "metadata": {},
   "source": [
    "Let's write 2 helper functions of calculating and printing evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0564f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "def print_evaluation_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error: {mse:.4f}')\n",
    "    print(f'R-squared: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd27707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Calculate and print the classification metrics\n",
    "def print_classification_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'ROC AUC Score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_regression(trainX, trainY, testX, testY):\n",
    "    # Create a linear regression model\n",
    "    linear_reg = LinearRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    linear_reg.fit(trainX, trainY)\n",
    "\n",
    "    # Predict the target values for the test data\n",
    "    testY_pred = linear_reg.predict(testX)\n",
    "\n",
    "    # Since linear regression returns continuous values, we need to convert the predictions into binary classification\n",
    "    lin_testY_pred_binary = (testY_pred >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate and print the evaluation and classification metrics\n",
    "    print_evaluation_metrics(testY, testY_pred)\n",
    "    print_classification_metrics(testY, lin_testY_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e5500",
   "metadata": {},
   "source": [
    "Next, we try to optimise the type of the regularization and the regularization strength ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def linear_regression_optimization(trainX, trainY, testX, testY, params):\n",
    "    # Create Ridge and Lasso models\n",
    "    ridge = Ridge()\n",
    "    lasso = Lasso()\n",
    "\n",
    "    # Create GridSearchCV objects for Ridge and Lasso\n",
    "    ridge_grid = GridSearchCV(ridge, params, scoring='neg_mean_squared_error', cv=5)\n",
    "    lasso_grid = GridSearchCV(lasso, params, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "    # Fit the GridSearchCV objects to the training data\n",
    "    ridge_grid.fit(trainX, trainY)\n",
    "    lasso_grid.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best hyperparameters and models\n",
    "    best_ridge_params = ridge_grid.best_params_\n",
    "    best_lasso_params = lasso_grid.best_params_\n",
    "    best_ridge_model = ridge_grid.best_estimator_\n",
    "    best_lasso_model = lasso_grid.best_estimator_\n",
    "\n",
    "    print(f'Best Ridge parameters: {best_ridge_params}')\n",
    "    print(f'Best Lasso parameters: {best_lasso_params}')\n",
    "    \n",
    "    # Make predictions using the best Ridge and Lasso models\n",
    "    ridge_testY_pred = best_ridge_model.predict(testX)\n",
    "    lasso_testY_pred = best_lasso_model.predict(testX)\n",
    "\n",
    "    # Convert the continuous predictions into binary classification\n",
    "    ridge_testY_pred_binary = (ridge_testY_pred >= 0.5).astype(int)\n",
    "    lasso_testY_pred_binary = (lasso_testY_pred >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate and print the evaluation metrics for Ridge model\n",
    "    print(\"Ridge Model:\")\n",
    "    print_evaluation_metrics(testY, ridge_testY_pred)\n",
    "    print_classification_metrics(testY, ridge_testY_pred_binary)\n",
    "\n",
    "    # Calculate and print the evaluation metrics for Lasso model\n",
    "    print(\"\\nLasso Model:\")\n",
    "    print_evaluation_metrics(testY, lasso_testY_pred)\n",
    "    print_classification_metrics(testY, lasso_testY_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe1741",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d314d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression(trainX, trainY, testX, testY):\n",
    "    # Create a logistic regression model\n",
    "    logistic_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    logistic_reg.fit(trainX, trainY.ravel())\n",
    "    \n",
    "    # Predict the target values for the test data\n",
    "    testY_pred = logistic_reg.predict(testX)\n",
    "\n",
    "    # Calculate and print the evaluation metrics\n",
    "    print_classification_metrics(testY, testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_optimization(trainX, trainY, testX, testY, params):\n",
    "    # Create a logistic regression model\n",
    "    logistic_reg = LogisticRegression(max_iter=3000)\n",
    "\n",
    "    # Create a GridSearchCV object for logistic regression\n",
    "    logistic_grid = GridSearchCV(logistic_reg, params, scoring='accuracy', cv=5)\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    logistic_grid.fit(trainX, trainY.ravel())\n",
    "\n",
    "    # Get the best hyperparameters and model\n",
    "    best_logistic_params = logistic_grid.best_params_\n",
    "    best_logistic_model = logistic_grid.best_estimator_\n",
    "\n",
    "    print(f'Best logistic regression parameters: {best_logistic_params}')\n",
    "    \n",
    "    logistic_testY_pred = best_logistic_model.predict(testX)\n",
    "\n",
    "    print_classification_metrics(testY, logistic_testY_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721f035",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svm(trainX, trainY, testX, testY):\n",
    "    # Create a Support vector model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    svm.fit(trainX, trainY.ravel())\n",
    "\n",
    "    # Predict the target values for the test data\n",
    "    testY_pred = svm.predict(testX)\n",
    "\n",
    "    # Calculate and print the evaluation metrics\n",
    "    print_classification_metrics(testY, testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30227a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svm_optimization(trainX, trainY, testX, testY, params):\n",
    "    # Create a Support vector model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Create a GridSearchCV object for SVM\n",
    "    svm_grid = GridSearchCV(svm, params, scoring='accuracy', cv=5)\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    svm_grid.fit(trainX, trainY.ravel())\n",
    "\n",
    "    # Get the best hyperparameters and model\n",
    "    best_svm_params = svm_grid.best_params_\n",
    "    best_svm_model = svm_grid.best_estimator_\n",
    "\n",
    "    print(f'Best SVM parameters: {best_svm_params}')\n",
    "    \n",
    "    print('Testing predictions:')\n",
    "    svm_testY_pred = best_svm_model.predict(testX)\n",
    "    print_classification_metrics(testY, svm_testY_pred)\n",
    "\n",
    "    print('Training predictions:')\n",
    "    svm_trainY_pred = best_svm_model.predict(trainX)\n",
    "    print_classification_metrics(trainY, svm_trainY_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53289e1e",
   "metadata": {},
   "source": [
    "### Neural Network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4702d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def nn(trainX, trainY, testX, testY):\n",
    "    # Create a neural network classifier model\n",
    "    mlp = MLPClassifier(max_iter = 2000, solver = 'adam')\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    mlp.fit(trainX, trainY.ravel())\n",
    "\n",
    "    # Predict the target values for the test data\n",
    "    testY_pred_nn = mlp.predict(testX)\n",
    "\n",
    "    # Calculate and print the evaluation metrics\n",
    "    print_classification_metrics(testY, testY_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def nn_optimization(trainX, trainY, testX, testY, params):\n",
    "    # Create a neural network classifier model\n",
    "    mlp = MLPClassifier(max_iter = 3000, solver = 'adam')\n",
    "\n",
    "    # Create a GridSearchCV object for the neural network classifier\n",
    "    mlp_grid = GridSearchCV(mlp, params, scoring='accuracy', cv=5)\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    mlp_grid.fit(trainX, trainY.ravel())\n",
    "\n",
    "    # Get the best hyperparameters and model\n",
    "    best_mlp_params = mlp_grid.best_params_\n",
    "    print(\"Best NN params:\" + str(best_mlp_params))\n",
    "    best_mlp_model = mlp_grid.best_estimator_\n",
    "    \n",
    "    print('Testing predictions:')\n",
    "    neural_network_testY_pred = best_mlp_model.predict(testX)\n",
    "    print_classification_metrics(testY, neural_network_testY_pred)\n",
    "    print('Training predictions:')\n",
    "    neural_network_trainY_pred = best_mlp_model.predict(trainX)\n",
    "    print_classification_metrics(trainY, neural_network_trainY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(trainX, trainY, testX, testY):\n",
    "    print(\"LINEAR REGRESSION:\")\n",
    "    linear_regression(trainX, trainY, testX, testY)\n",
    "    \n",
    "    print(\"\\nLINEAR REGRESSION - HYPERPARAMETERS OPTIMIZATION:\")\n",
    "    # Define the hyperparameters to optimize\n",
    "    linreg_params = {\n",
    "        'alpha': np.logspace(-4, 4, 9)  # Regularization strength\n",
    "    }\n",
    "    linear_regression_optimization(trainX, trainY, testX, testY, linreg_params)\n",
    "\n",
    "    \n",
    "    print(\"\\nLOGISTIC REGRESSION:\")\n",
    "    logistic_regression(trainX, trainY, testX, testY)\n",
    "\n",
    "    print(\"\\nLOGISTIC REGRESSION - HYPERPARAMETERS OPTIMIZATION:\")\n",
    "    # Define the hyperparameters to optimize\n",
    "    logreg_params = {\n",
    "        'C': np.logspace(-4, 4, 9),  # Inverse of regularization strength\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }\n",
    "    logistic_regression_optimization(trainX, trainY, testX, testY, logreg_params)\n",
    "\n",
    "    \n",
    "    print(\"\\nSVM:\")\n",
    "    svm(trainX, trainY, testX, testY)\n",
    "\n",
    "    print(\"\\nSVM - HYPERPARAMETERS OPTIMIZATION:\")\n",
    "    # Define the hyperparameters to optimize\n",
    "    svm_params = {\n",
    "        'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel function\n",
    "        'gamma': ['scale', 'auto']  # Kernel coefficient for rbf, poly and sigmoid\n",
    "    }\n",
    "    svm_optimization(trainX, trainY, testX, testY, svm_params)\n",
    "\n",
    "    \n",
    "    print(\"\\nNEURAL NETWORKS:\")\n",
    "    nn(trainX, trainY, testX, testY)\n",
    "\n",
    "    print(\"\\nNEURAL NETWORKS - HYPERPARAMETERS OPTIMIZATION:\")\n",
    "    # Define the hyperparameters to optimize\n",
    "    nn_params = {\n",
    "        'hidden_layer_sizes': [(5,), (17,), (34, 17), (5, 5)],  # Number of neurons in each hidden layer\n",
    "        #'activation': ['identity', 'logistic', 'tanh', 'relu'],  # Activation function for the hidden layer\n",
    "        'solver': ['adam', 'sgd'],  # Optimizer for weight optimization\n",
    "        'alpha': [0.0001, 0.001, 0.01],  # L2 penalty (regularization term)\n",
    "        #'learning_rate': ['constant', 'invscaling', 'adaptive']  # Learning rate schedule for weight updates\n",
    "    }\n",
    "    nn_optimization(trainX, trainY, testX, testY, nn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b192ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "analyze_dataset(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f574d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_dataset(X_cleveland, Y_cleveland, X_switzerland, Y_switzerland)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9caa6",
   "metadata": {},
   "source": [
    "## Neural Network Classifier - using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a281d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "trainX, valX, trainY, valY = train_test_split(trainX_fully_preprocessed, trainY_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "valX = scaler.transform(valX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "trainX = torch.tensor(trainX, dtype=torch.float32)\n",
    "trainY = torch.tensor(trainY.values, dtype=torch.float32)\n",
    "valX = torch.tensor(valX, dtype=torch.float32)\n",
    "valY = torch.tensor(valY.values, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = TensorDataset(trainX, trainY)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(valX, valY)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(trainX.shape[1], 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 2000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    # Training phase\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs).squeeze()\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cost function trajectory over iterations\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing phase\n",
    "testX_fully_preprocessed = torch.tensor(testX_fully_preprocessed, dtype=torch.float32).to(device)\n",
    "testY_pred_nn = net(testX_fully_preprocessed).squeeze().cpu().detach().numpy()\n",
    "testY_pred_nn_binary = (testY_pred_nn >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print_classification_metrics(testY_binary, testY_pred_nn_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9962f5f4",
   "metadata": {},
   "source": [
    "Next, we do hyperparameter optimization for Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes, output_size, activation_function, alpha):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        previous_size = input_size\n",
    "        for size in hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(previous_size, size))\n",
    "            layers.append(activation_function)\n",
    "            previous_size = size\n",
    "\n",
    "        layers.append(nn.Linear(previous_size, output_size))\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn_model(hidden_layer_sizes, activation, solver, alpha, learning_rate):\n",
    "    # Convert activation string to corresponding PyTorch activation function\n",
    "    activation_mapping = {\n",
    "        'identity': torch.nn.Identity(),\n",
    "        'logistic': torch.nn.Sigmoid(),\n",
    "        'tanh': torch.nn.Tanh(),\n",
    "        'relu': torch.nn.ReLU()\n",
    "    }\n",
    "    activation_function = activation_mapping[activation]\n",
    "\n",
    "    # Create the model\n",
    "    model = SimpleNN(input_size, hidden_layer_sizes, output_size, activation_function, alpha)\n",
    "\n",
    "    # Set the optimizer\n",
    "    optimizer_mapping = {\n",
    "        'adam': torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=alpha),\n",
    "        'sgd': torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=alpha)\n",
    "    }\n",
    "    optimizer = optimizer_mapping[solver]\n",
    "\n",
    "    # Set the learning rate scheduler (optional)\n",
    "    learning_rate_schedule_mapping = {\n",
    "        'constant': torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=1),\n",
    "        'invscaling': torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9),\n",
    "        'adaptive': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    }\n",
    "    scheduler = learning_rate_schedule_mapping[learning_rate]\n",
    "\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(model, optimizer, scheduler, train_loader, val_loader, epochs=100, device=\"cpu\"):\n",
    "    criterion = nn.BCELoss()\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize the running_loss variable\n",
    "    running_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training loop\n",
    "        for batch in train_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Unsqueeze targets to match output shape\n",
    "            targets = targets.unsqueeze(1)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Unsqueeze labels to match output shape\n",
    "            labels = labels.unsqueeze(1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "        scheduler.step(val_running_loss)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_running_loss / len(val_loader)}')\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(1,), (2,), (1, 1), (2, 2)])\n",
    "    \n",
    "    #activation = trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu'])\n",
    "    activation = trial.suggest_categorical('activation', ['relu'])\n",
    "    \n",
    "    #solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "    solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "\n",
    "    alpha = trial.suggest_float('alpha', 0.0001, 0.01)\n",
    "    \n",
    "    #learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive'])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'adaptive'])\n",
    "    \n",
    "    input_size = trainX_fully_preprocessed.shape[1]\n",
    "    output_size = 1\n",
    "\n",
    "    # Create the model with suggested hyperparameters\n",
    "    model = create_nn_model(hidden_layer_sizes, activation, solver, alpha, learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    train_nn_model(model, trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    valY_pred_nn = model(torch.tensor(valX_fully_preprocessed, dtype=torch.float32)).detach().numpy()\n",
    "    valY_pred_nn_binary = (valY_pred_nn >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate the negative accuracy to minimize\n",
    "    neg_accuracy = -accuracy_score(valY_binary, valY_pred_nn_binary)\n",
    "\n",
    "    return neg_accuracy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990717b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(1,), (2,), (1, 1), (2, 2)])\n",
    "    activation_function = trial.suggest_categorical('activation', [nn.Identity(), nn.Sigmoid(), nn.Tanh(), nn.ReLU()])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd'])\n",
    "    alpha = trial.suggest_float('alpha', 0.0001, 0.01)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "\n",
    "    input_size = trainX_fully_preprocessed.shape[1]\n",
    "    output_size = 1\n",
    "\n",
    "    # Create the model with suggested hyperparameters\n",
    "    model = SimpleNN(input_size, hidden_layer_sizes, output_size, activation_function, alpha)\n",
    "\n",
    "    # Create the optimizer\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=alpha)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=alpha)\n",
    "\n",
    "    # Create the learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    train_nn_model(model, optimizer, scheduler, train_loader, val_loader, epochs=100)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs >= 0.5).cpu().numpy().astype(int)\n",
    "            val_preds.extend(preds)\n",
    "            val_true.extend(targets.cpu().numpy())\n",
    "    \n",
    "    valY_pred_nn_binary = np.array(val_preds).reshape(-1)\n",
    "    valY_binary = np.array(val_true).reshape(-1)\n",
    "\n",
    "    # Calculate the negative accuracy to minimize\n",
    "    neg_accuracy = -accuracy_score(valY_binary, valY_pred_nn_binary)\n",
    "\n",
    "    return neg_accuracy\n",
    "\n",
    "# Create a study and run optimization\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding negative accuracy\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(f'Best hyperparameters: {best_params}')\n",
    "print(f'Best negative accuracy: {best_value}')\n",
    "\n",
    "# Train the model with the best hyperparameters on the full training set\n",
    "best_model = create_nn_model(*best_params.values())\n",
    "train_nn_model(best_model, trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Make predictions on the test set\n",
    "testY_pred_nn = best_model(torch.tensor(testX_fully_preprocessed, dtype=torch.float32)).detach().numpy()\n",
    "testY_pred_nn_binary = (testY_pred_nn >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print_classification_metrics(testY_binary, testY_pred_nn_binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891e0ca",
   "metadata": {},
   "source": [
    "# Results comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf836d",
   "metadata": {},
   "source": [
    "Compare results of all classifications only for optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin regression\n",
    "print('lin reg lasso')\n",
    "# print_classification_metrics(testY_binary, lasso_testY_pred_binary)\n",
    "print('')\n",
    "print('lin reg ridge')\n",
    "# print_classification_metrics(testY_binary, ridge_testY_pred_binary)\n",
    "print('')\n",
    "# log regression\n",
    "print('log reg')\n",
    "# print_classification_metrics(testY_binary, logistic_testY_pred)\n",
    "print('')\n",
    "# svm\n",
    "print('svm')\n",
    "# print_classification_metrics(testY_binary, svm_testY_pred)\n",
    "print('')\n",
    "# nn\n",
    "print('neural network')\n",
    "# print_classification_metrics(testY_binary, neural_network_testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(model, testX, testY, threshold=0.5):\n",
    "    '''\n",
    "    Evaluates a binary classification model on the test set\n",
    "    Returns a dictionary with the evaluation metrics\n",
    "    '''\n",
    "    predY = model.predict(testX) > threshold\n",
    "    \n",
    "    acc = accuracy_score(testY, predY)\n",
    "    prec = precision_score(testY, predY)\n",
    "    rec = recall_score(testY, predY)\n",
    "    f1 = f1_score(testY, predY)\n",
    "    roc_auc = roc_auc_score(testY, predY)\n",
    "    \n",
    "    return {'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC Score': roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Evaluation metrics dictionary for each model\n",
    "lasso_metrics = evaluate_classification_model(best_lasso_model, testX_fully_preprocessed, testY_binary)\n",
    "ridge_metrics = evaluate_classification_model(best_ridge_model, testX_fully_preprocessed, testY_binary)\n",
    "logistic_metrics = evaluate_classification_model(best_logistic_model, testX_fully_preprocessed, testY_binary)\n",
    "svm_metrics = evaluate_classification_model(best_svm_model, testX_fully_preprocessed, testY_binary)\n",
    "nn_metrics = evaluate_classification_model(best_mlp_model, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "# Create a pandas DataFrame for the evaluation metrics\n",
    "results = pd.DataFrame({'Model': ['Lasso Regression', 'Ridge Regression', 'Logistic Regression', 'SVM', 'Neural Network'],\n",
    "                   'Accuracy': [lasso_metrics['Accuracy'], ridge_metrics['Accuracy'], logistic_metrics['Accuracy'], svm_metrics['Accuracy'], nn_metrics['Accuracy']],\n",
    "                   'Precision': [lasso_metrics['Precision'], ridge_metrics['Precision'], logistic_metrics['Precision'], svm_metrics['Precision'], nn_metrics['Precision']],\n",
    "                   'Recall': [lasso_metrics['Recall'], ridge_metrics['Recall'], logistic_metrics['Recall'], svm_metrics['Recall'], nn_metrics['Recall']],\n",
    "                   'F1 Score': [lasso_metrics['F1 Score'], ridge_metrics['F1 Score'], logistic_metrics['F1 Score'], svm_metrics['F1 Score'], nn_metrics['F1 Score']],\n",
    "                   'ROC AUC Score': [lasso_metrics['ROC AUC Score'], ridge_metrics['ROC AUC Score'], logistic_metrics['ROC AUC Score'], svm_metrics['ROC AUC Score'], nn_metrics['ROC AUC Score']]})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb269dd",
   "metadata": {},
   "source": [
    "# Here are the confusion matrices for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lasso = confusion_matrix(testY_binary,lasso_testY_pred_binary)\n",
    "cm_ridge = confusion_matrix(testY_binary,ridge_testY_pred_binary)\n",
    "cm_log = confusion_matrix(testY_binary,logistic_testY_pred)\n",
    "cm_svm = confusion_matrix(testY_binary,svm_testY_pred)\n",
    "cm_nn = confusion_matrix(testY_binary,neural_network_testY_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_lasso.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_lasso.flatten()/np.sum(cm_lasso)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_lasso, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_ridge.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_ridge.flatten()/np.sum(cm_ridge)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_ridge, annot=labels, fmt=\"\", cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_log.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_log.flatten()/np.sum(cm_log)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_log, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_svm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_svm.flatten()/np.sum(cm_svm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_svm, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_nn.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_nn.flatten()/np.sum(cm_nn)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_nn, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc1912",
   "metadata": {},
   "source": [
    "# Train models for Cleveland dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d227ab5",
   "metadata": {},
   "source": [
    "Now, to not change all variable names, we overwrite the variable names of the fully preprocessed dataset with the Cleveland preprocessed dataset. This step is essential!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_fully_preprocessed = trainX_fully_preprocessed_cl\n",
    "testX_fully_preprocessed = testX_fully_preprocessed_cl\n",
    "trainY_binary = trainY_binary_cl\n",
    "testY_binary = testY_binary_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX_fully_preprocessed.shape)\n",
    "print(testX_fully_preprocessed.shape)\n",
    "print(trainY_binary.shape)\n",
    "print(testY_binary.shape)\n",
    "\n",
    "#print(trainX_fully_preprocessed_cl.shape)\n",
    "#print(testX_fully_preprocessed_cl.shape)\n",
    "#print(trainY_binary_cl.shape)\n",
    "#print(testY_binary_cl.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd0de0",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear regression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_reg.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "testY_pred = linear_reg.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Since linear regression returns continuous values, we need to convert the predictions into binary classification\n",
    "lin_testY_pred_binary = (testY_pred >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the evaluation and classification metrics\n",
    "print_evaluation_metrics(testY_binary, testY_pred)\n",
    "print_classification_metrics(testY_binary, lin_testY_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_linear = confusion_matrix(testY_binary,lin_testY_pred_binary)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_linear.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_linear.flatten()/np.sum(cm_linear)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_linear, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "plt.savefig('cm_lin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming trainX_fully_preprocessed, trainY_binary are loaded as NumPy arrays or pandas DataFrames\n",
    "\n",
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    'alpha': np.logspace(-4, 4, 9)  # Regularization strength\n",
    "}\n",
    "\n",
    "# Create Ridge and Lasso models\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "# Create GridSearchCV objects for Ridge and Lasso\n",
    "ridge_grid = GridSearchCV(ridge, params, scoring='neg_mean_squared_error', cv=5)\n",
    "lasso_grid = GridSearchCV(lasso, params, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV objects to the training data\n",
    "ridge_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "lasso_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and models\n",
    "best_ridge_params = ridge_grid.best_params_\n",
    "best_lasso_params = lasso_grid.best_params_\n",
    "best_ridge_model = ridge_grid.best_estimator_\n",
    "best_lasso_model = lasso_grid.best_estimator_\n",
    "\n",
    "print(f'Best Ridge parameters: {best_ridge_params}')\n",
    "print(f'Best Lasso parameters: {best_lasso_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the best Ridge and Lasso models\n",
    "ridge_testY_pred = best_ridge_model.predict(testX_fully_preprocessed)\n",
    "lasso_testY_pred = best_lasso_model.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Convert the continuous predictions into binary classification\n",
    "ridge_testY_pred_binary = (ridge_testY_pred >= 0.5).astype(int)\n",
    "lasso_testY_pred_binary = (lasso_testY_pred >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the evaluation metrics for Ridge model\n",
    "print(\"Ridge Model:\")\n",
    "print_evaluation_metrics(testY_binary, ridge_testY_pred)\n",
    "print_classification_metrics(testY_binary, ridge_testY_pred_binary)\n",
    "\n",
    "# Calculate and print the evaluation metrics for Lasso model\n",
    "print(\"\\nLasso Model:\")\n",
    "print_evaluation_metrics(testY_binary, lasso_testY_pred)\n",
    "print_classification_metrics(testY_binary, lasso_testY_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7149e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lasso = confusion_matrix(testY_binary,lasso_testY_pred_binary)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_lasso.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_lasso.flatten()/np.sum(cm_lasso)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_lasso, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "plt.savefig('cm_lasso.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ridge = confusion_matrix(testY_binary,ridge_testY_pred_binary)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_ridge.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_ridge.flatten()/np.sum(cm_ridge)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_ridge, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "plt.savefig('cm_ridge.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9257d6",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "logistic_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logistic_reg.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "testY_pred_log = logistic_reg.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print_classification_metrics(testY_binary, testY_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    'C': np.logspace(-4, 4, 9),  # Inverse of regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Create a logistic regression model\n",
    "logistic_reg = LogisticRegression(max_iter=3000)\n",
    "\n",
    "# Create a GridSearchCV object for logistic regression\n",
    "logistic_grid = GridSearchCV(logistic_reg, params, scoring='accuracy', cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "logistic_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_logistic_params = logistic_grid.best_params_\n",
    "best_logistic_model = logistic_grid.best_estimator_\n",
    "\n",
    "print(f'Best logistic regression parameters: {best_logistic_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20773a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_testY_pred = best_logistic_model.predict(testX_fully_preprocessed)\n",
    "\n",
    "print_classification_metrics(testY_binary, logistic_testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9023eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_log = confusion_matrix(testY_binary,logistic_testY_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_log.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_log.flatten()/np.sum(cm_log)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_log, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "plt.savefig('cm_log.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258fb84d",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Support vector model\n",
    "svm = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "testY_pred_svm = svm.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print_classification_metrics(testY_binary, testY_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ca1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    'C': [0.1, 1, 10,],  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel function\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient for rbf, poly and sigmoid\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object for SVM\n",
    "svm_grid = GridSearchCV(svm, params, scoring='accuracy', cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "svm_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_svm_params = svm_grid.best_params_\n",
    "best_svm_model = svm_grid.best_estimator_\n",
    "\n",
    "print(f'Best SVM parameters: {best_svm_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_testY_pred = best_svm_model.predict(testX_fully_preprocessed)\n",
    "print_classification_metrics(testY_binary, svm_testY_pred)\n",
    "\n",
    "#svm_trainY_pred = best_svm_model.predict(trainX_fully_preprocessed)\n",
    "#print_classification_metrics(trainY_binary, svm_trainY_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_svm = confusion_matrix(testY_binary,svm_testY_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_svm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_svm.flatten()/np.sum(cm_svm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_svm, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "plt.savefig('cm_svm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b47084",
   "metadata": {},
   "source": [
    "NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430decd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier model\n",
    "mlp = MLPClassifier(max_iter = 2000, solver = 'adam')\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "testY_pred_nn = mlp.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print_classification_metrics(testY_binary, testY_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to optimize\n",
    "#params = {\n",
    "#    'hidden_layer_sizes': [(30,30), (30,30,17), (30, 17, 8, 4), (17, 17 , 17)],  # Number of neurons in each hidden layer\n",
    "#    'activation': ['identity', 'logistic', 'tanh', 'relu'],  # Activation function for the hidden layer\n",
    "#    'solver': ['adam', 'sgd'],  # Optimizer for weight optimization\n",
    "#    'alpha': [0.0001, 0.001, 0.01],  # L2 penalty (regularization term)\n",
    "#    'learning_rate': ['constant', 'invscaling', 'adaptive']  # Learning rate schedule for weight updates\n",
    "#}\n",
    "\n",
    "params = {\n",
    "    'hidden_layer_sizes': [(30,30), (30,30,17), (30,30,17,8)],  # Number of neurons in each hidden layer\n",
    "    'activation': ['identity'],  # Activation function for the hidden layer\n",
    "    'alpha': [0.00001, 0.0001],  # L2 penalty (regularization term)\n",
    "    'learning_rate': ['adaptive']  # Learning rate schedule for weight updates\n",
    "}\n",
    "\n",
    "\n",
    "# Create a neural network classifier model\n",
    "mlp = MLPClassifier(max_iter = 20000, solver = 'adam')\n",
    "\n",
    "# Create a GridSearchCV object for the neural network classifier\n",
    "mlp_grid = GridSearchCV(mlp, params, scoring='accuracy', cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "mlp_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_mlp_params = mlp_grid.best_params_\n",
    "best_mlp_model = mlp_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_testY_pred = best_mlp_model.predict(testX_fully_preprocessed)\n",
    "\n",
    "print_classification_metrics(testY_binary, neural_network_testY_pred)\n",
    "\n",
    "#print('')\n",
    "#neural_network_trainY_pred = best_mlp_model.predict(trainX_fully_preprocessed)\n",
    "\n",
    "#print_classification_metrics(trainY_binary, neural_network_trainY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4976f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_nn = confusion_matrix(testY_binary,neural_network_testY_pred)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_nn.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_nn.flatten()/np.sum(cm_nn)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_nn, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "plt.savefig('cm_nn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69182e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testY_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14192af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neural_network_testY_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c327d",
   "metadata": {},
   "source": [
    "Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08149a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Evaluation metrics dictionary for each model\n",
    "linear_metrics = evaluate_classification_model(linear_reg, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "lasso_metrics = evaluate_classification_model(best_lasso_model, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "ridge_metrics = evaluate_classification_model(best_ridge_model, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "logistic_metrics = evaluate_classification_model(best_logistic_model, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "svm_metrics = evaluate_classification_model(best_svm_model, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "nn_metrics = evaluate_classification_model(best_mlp_model, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "# Create a pandas DataFrame for the evaluation metrics\n",
    "results = pd.DataFrame({'Model': ['Linear Regression','Lasso Regression', 'Ridge Regression', 'Logistic Regression', 'SVM', 'Neural Network'],\n",
    "                   'Accuracy': [linear_metrics['Accuracy'], lasso_metrics['Accuracy'], ridge_metrics['Accuracy'], logistic_metrics['Accuracy'], svm_metrics['Accuracy'], nn_metrics['Accuracy']],\n",
    "                   'Precision': [linear_metrics['Precision'], lasso_metrics['Precision'], ridge_metrics['Precision'], logistic_metrics['Precision'], svm_metrics['Precision'], nn_metrics['Precision']],\n",
    "                   'Recall': [linear_metrics['Recall'], lasso_metrics['Recall'], ridge_metrics['Recall'], logistic_metrics['Recall'], svm_metrics['Recall'], nn_metrics['Recall']],\n",
    "                   'F1 Score': [linear_metrics['F1 Score'], lasso_metrics['F1 Score'], ridge_metrics['F1 Score'], logistic_metrics['F1 Score'], svm_metrics['F1 Score'], nn_metrics['F1 Score']],\n",
    "                   'ROC AUC Score': [linear_metrics['ROC AUC Score'], lasso_metrics['ROC AUC Score'], ridge_metrics['ROC AUC Score'], logistic_metrics['ROC AUC Score'], svm_metrics['ROC AUC Score'], nn_metrics['ROC AUC Score']]})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba844d5",
   "metadata": {},
   "source": [
    "## Feature selection for model accuracy improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4aa23",
   "metadata": {},
   "source": [
    "print(trainX_fully_preprocessed_cl)\n",
    "print(testX_fully_preprocessed_cl)\n",
    "print(trainY_binary_cl)\n",
    "print(testY_binary_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
