{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df83d65",
   "metadata": {},
   "source": [
    "This is the project for Machine Learning at UA. \n",
    "First, we import the datasets into the notebook after we downloaded the files from the website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e5d5b",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# read csv files\n",
    "cleveland_df   = pd.read_csv(\"processed.cleveland.data\", header=None, na_values =[\"?\", -9.0])\n",
    "switzerland_df = pd.read_csv(\"processed.switzerland.data\", header=None, na_values =[\"?\", -9.0])\n",
    "va_df          = pd.read_csv(\"processed.va.data\", header=None, na_values =[\"?\", -9.0])\n",
    "hungarian_df   = pd.read_csv(\"processed.hungarian.data\", header=None, na_values =[\"?\", -9.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65794d",
   "metadata": {},
   "source": [
    "Now we need to organize the data and add headers to the data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column to keep track of the source of the data\n",
    "cleveland_df[\"Source\"] = \"cleveland\"\n",
    "switzerland_df[\"Source\"] = \"switzerland\"\n",
    "va_df[\"Source\"] = \"va\"\n",
    "hungarian_df[\"Source\"] = \"hungarian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add headers to the data frames\n",
    "headers = {0 : \"age\",\n",
    "               1 : \"sex\",\n",
    "               2 : \"cp\",\n",
    "               3 : \"trestbps\",\n",
    "               4 : \"chol\",\n",
    "               5 : \"fbs\",\n",
    "               6 : \"restecg\",\n",
    "               7 : \"thalach\",\n",
    "               8 : \"exang\",\n",
    "               9 : \"oldpeak\",\n",
    "               10 : \"slope\",\n",
    "               11 : \"ca\",\n",
    "               12 : \"thal\",\n",
    "               13 : \"diagnosis\"}\n",
    "\n",
    "cleveland_df = cleveland_df.rename(columns=headers)\n",
    "switzerland_df = switzerland_df.rename(columns=headers)\n",
    "va_df = va_df.rename(columns=headers)\n",
    "hungarian_df = hungarian_df.rename(columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62c848",
   "metadata": {},
   "source": [
    "Now we want to combine the different datasets from Cleveland, Switzerland, Va and Hungary into one big dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ff3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df = pd.concat([cleveland_df, switzerland_df, va_df, hungarian_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0df4aa",
   "metadata": {},
   "source": [
    "Next, we want to look at some details of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475ba4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(heart_disease_df.head())\n",
    "print(heart_disease_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21f9c2",
   "metadata": {},
   "source": [
    "Next, let's use the command from the lecture to describe the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e38880",
   "metadata": {},
   "source": [
    "Let's collect some more information concerning the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ae86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heart_disease_df.shape)\n",
    "print(heart_disease_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76372ce2",
   "metadata": {},
   "source": [
    "Some more analytics. There are 920 observations with 15 14 features each, resulting in one diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39807cd6",
   "metadata": {},
   "source": [
    "Analyse the Pearson correlation coefficient, to find connections within the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(heart_disease_df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004b15e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rs.rand(10, 10))\n",
    "corr = heart_disease_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7292f",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "heart_disease_df.hist(figsize=(10,10))\n",
    "plt.show()\n",
    "plt.savefig('heart_disease_hist.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ce741",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.head()\n",
    "sns.set_style('whitegrid')\n",
    "sns.histplot(heart_disease_df['diagnosis'], kde = False, color ='red', bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the age ranges for grouping\n",
    "age_bins = [20, 30, 40, 50, 60, 70, 80]\n",
    "\n",
    "# Create a new column 'age_group' based on age bins\n",
    "heart_disease_df['age_group'] = pd.cut(heart_disease_df['age'], bins=age_bins)\n",
    "\n",
    "# Create the boxplot with age group on x-axis and diagnosis on y-axis\n",
    "sns.boxplot(x='age_group', y='diagnosis', data=heart_disease_df)\n",
    "heart_disease_df= heart_disease_df.drop('age_group', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f35937",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Group the data by age and calculate the mean, median of a column for each group\n",
    "age_stats_df = heart_disease_df.groupby('age')['diagnosis'].agg(['mean', 'median']).reset_index()\n",
    "\n",
    "# Plot the graph using seaborn lineplot\n",
    "sns.lineplot(x='age', y='mean', data=age_stats_df, label='Average')\n",
    "sns.lineplot(x='age', y='median', data=age_stats_df, label='Median')\n",
    "sns.lineplot(x='age', y='diagnosis', data=heart_disease_df, estimator=None, alpha=0.2, color='gray')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbabb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='ca',y='diagnosis',data=heart_disease_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08db8ee",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ec8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUOUS_FACTORS = [\"age\", \"chol\", \"oldpeak\", \"thalach\", \"trestbps\"]\n",
    "DISCRETE_FACTORS = [\"ca\", \"cp\", \"exang\", \"fbs\", \"restecg\", \"sex\", \"slope\", \"thal\"]\n",
    "TARGET = [\"diagnosis\"]\n",
    "\n",
    " \n",
    "train, test = sklearn.model_selection.train_test_split(heart_disease_df, test_size=.2, random_state=10)\n",
    "\n",
    "# split the data into the X and Y variables\n",
    "trainY = train[\"diagnosis\"].copy()\n",
    "trainX = train.drop(\"diagnosis\", axis=1)\n",
    "testY = test[\"diagnosis\"].copy()\n",
    "testX = test.drop(\"diagnosis\", axis=1)\n",
    "\n",
    "# Handle the discrete and continuous variables seperatly\n",
    "trainX_continuous = trainX[CONTINUOUS_FACTORS]\n",
    "trainX_discrete = trainX[DISCRETE_FACTORS].fillna(value=5) #For all the discrete values, replace missing values with 5\n",
    "testX_continuous = testX[CONTINUOUS_FACTORS]\n",
    "testX_discrete = testX[DISCRETE_FACTORS].fillna(value=5) #For all the discrete values, replace missing values with 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf66709",
   "metadata": {},
   "outputs": [],
   "source": [
    " # For continuous variables, replace missing values with the median and then normalize by subtracting the mean and dividing by the standard deviation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "continuous_Pipeline = sklearn.pipeline.Pipeline( [(\"imputer\", sklearn.impute.SimpleImputer(strategy=\"median\")),\n",
    "                                             (\"scaler\", sklearn.preprocessing.StandardScaler())\n",
    "                                            ]\n",
    "                                           )\n",
    "trainX_continuous_scaled = continuous_Pipeline.fit_transform(trainX_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeee4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for discrete variables, one-hot encode the data\n",
    "discrete_Pipeline = sklearn.pipeline.Pipeline( [(\"one_hot\", sklearn.preprocessing.OneHotEncoder(handle_unknown ='ignore'))\n",
    "                                            ]\n",
    "                                           )\n",
    "trainX_discrete_one_hot = discrete_Pipeline.fit_transform(trainX_discrete)\n",
    "\n",
    "print(np.size(trainX_discrete, 1))\n",
    "print(np.size(trainX_discrete_one_hot, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df424e",
   "metadata": {},
   "source": [
    "The one hot encoding increases the number of features from 8 to 29, since artificially zeros are introduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_fully_preprocessed = np.concatenate((trainX_continuous_scaled, trainX_discrete_one_hot.toarray()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test data, note the use of transform instead of fit_transform\n",
    "testX_continuous_scaled = continuous_Pipeline.transform(testX_continuous)\n",
    "testX_discrete_one_hot = discrete_Pipeline.transform(testX_discrete)\n",
    "testX_fully_preprocessed = np.concatenate((testX_continuous_scaled, testX_discrete_one_hot.toarray()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfb168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Y varialbe to a binary varible\n",
    "trainY_binary = (trainY>0) # True if they have heart disease, False otherwide\n",
    "testY_binary = (testY>0) # True if they have heart disease, False otherwide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96375a09",
   "metadata": {},
   "source": [
    "Preprocessing done. There are two datasets: trainY_binary and trainY. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80798f02",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f5d95",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea216a0a",
   "metadata": {},
   "source": [
    "Let's write 2 helper functions of calculating and printing evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0564f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "def print_evaluation_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error: {mse:.4f}')\n",
    "    print(f'R-squared: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd27707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Calculate and print the classification metrics\n",
    "def print_classification_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'ROC AUC Score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc407b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX_fully_preprocessed.shape)\n",
    "print(testX_fully_preprocessed.shape)\n",
    "print(trainY_binary.shape)\n",
    "print(testY_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear regression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_reg.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the train and test data\n",
    "trainY_pred = linear_reg.predict(trainX_fully_preprocessed)\n",
    "testY_pred = linear_reg.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Since linear regression returns continuous values, we need to convert the predictions into binary classification\n",
    "lin_trainY_pred_binary = (trainY_pred >= 0.5).astype(int)\n",
    "lin_testY_pred_binary = (testY_pred >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the evaluation and classification metrics\n",
    "print(\"TRAINING DATA:\")\n",
    "print_evaluation_metrics(trainY_binary, trainY_pred)\n",
    "print_classification_metrics(trainY_binary, lin_trainY_pred_binary)\n",
    "print(\"\\nTEST DATA:\")\n",
    "print_evaluation_metrics(testY_binary, testY_pred)\n",
    "print_classification_metrics(testY_binary, lin_testY_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e5500",
   "metadata": {},
   "source": [
    "Next, we try to optimise the type of the regularization and the regularization strength ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming trainX_fully_preprocessed, trainY_binary are loaded as NumPy arrays or pandas DataFrames\n",
    "\n",
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    'alpha': np.logspace(-4, 4, 9)  # Regularization strength\n",
    "}\n",
    "\n",
    "# Create Ridge and Lasso models\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "# Create GridSearchCV objects for Ridge and Lasso\n",
    "ridge_grid = GridSearchCV(ridge, params, scoring='neg_mean_squared_error', cv=5)\n",
    "lasso_grid = GridSearchCV(lasso, params, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV objects to the training data\n",
    "ridge_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "lasso_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and models\n",
    "best_ridge_params = ridge_grid.best_params_\n",
    "best_lasso_params = lasso_grid.best_params_\n",
    "best_ridge_model = ridge_grid.best_estimator_\n",
    "best_lasso_model = lasso_grid.best_estimator_\n",
    "\n",
    "print(f'Best Ridge parameters: {best_ridge_params}')\n",
    "print(f'Best Lasso parameters: {best_lasso_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the best Ridge and Lasso models\n",
    "ridge_testY_pred = best_ridge_model.predict(testX_fully_preprocessed)\n",
    "lasso_testY_pred = best_lasso_model.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Convert the continuous predictions into binary classification\n",
    "ridge_testY_pred_binary = (ridge_testY_pred >= 0.5).astype(int)\n",
    "lasso_testY_pred_binary = (lasso_testY_pred >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the evaluation metrics for Ridge model\n",
    "print(\"Ridge Model:\")\n",
    "print_evaluation_metrics(testY_binary, ridge_testY_pred)\n",
    "print_classification_metrics(testY_binary, ridge_testY_pred_binary)\n",
    "\n",
    "# Calculate and print the evaluation metrics for Lasso model\n",
    "print(\"\\nLasso Model:\")\n",
    "print_evaluation_metrics(testY_binary, lasso_testY_pred)\n",
    "print_classification_metrics(testY_binary, lasso_testY_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe1741",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d314d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "logistic_reg = LogisticRegression(solver='saga', max_iter=3000, verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logistic_reg.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the training and test data\n",
    "trainY_pred = logistic_reg.predict(trainX_fully_preprocessed)\n",
    "testY_pred = logistic_reg.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"TRAIN DATA:\")\n",
    "print_classification_metrics(trainY_binary, trainY_pred)\n",
    "print(\"\\nTEST DATA:\")\n",
    "print_classification_metrics(testY_binary, testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    'C': np.logspace(-4, 4, 9),  # Inverse of regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Create a logistic regression model\n",
    "logistic_reg = LogisticRegression(max_iter=3000)\n",
    "\n",
    "# Create a GridSearchCV object for logistic regression\n",
    "logistic_grid = GridSearchCV(logistic_reg, params, scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "logistic_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_logistic_params = logistic_grid.best_params_\n",
    "best_logistic_model = logistic_grid.best_estimator_\n",
    "\n",
    "print(f'Best logistic regression parameters: {best_logistic_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efe4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target values for the training and test data\n",
    "logistic_trainY_pred = best_logistic_model.predict(trainX_fully_preprocessed)\n",
    "logistic_testY_pred = best_logistic_model.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"TRAIN DATA:\")\n",
    "print_classification_metrics(trainY_binary, logistic_trainY_pred)\n",
    "print(\"\\nTEST DATA:\")\n",
    "print_classification_metrics(testY_binary, logistic_testY_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721f035",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Support vector model\n",
    "svm = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "testY_pred = svm.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print_classification_metrics(testY_binary, testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30227a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel function\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient for rbf, poly and sigmoid\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object for SVM\n",
    "svm_grid = GridSearchCV(svm, params, scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "svm_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_svm_params = svm_grid.best_params_\n",
    "best_svm_model = svm_grid.best_estimator_\n",
    "\n",
    "\n",
    "print(f'Best SVM parameters: {best_svm_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_testY_pred = best_svm_model.predict(testX_fully_preprocessed)\n",
    "\n",
    "print_classification_metrics(testY_binary, svm_testY_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53289e1e",
   "metadata": {},
   "source": [
    "### Neural Network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4702d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier model\n",
    "mlp = MLPClassifier(max_iter = 2000, solver = 'adam')\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "trainY_pred_nn = mlp.predict(trainX_fully_preprocessed)\n",
    "testY_pred_nn = mlp.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"TRAIN DATA:\")\n",
    "print_classification_metrics(trainY_binary, trainY_pred_nn)\n",
    "print(\"\\nTEST DATA:\")\n",
    "print_classification_metrics(testY_binary, testY_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to optimize\n",
    "params = {\n",
    "    'hidden_layer_sizes': [(34,), (17,), (34, 17), (17, 8), (17, 8, 4), (34, 17, 8)],\n",
    "    'alpha': [0.001, 0.01, 0.1, 1],\n",
    "    'activation': ['relu'],\n",
    "    'learning_rate_init': [0.1],\n",
    "    'batch_size': [16],  # Different batch sizes\n",
    "}\n",
    "\n",
    "# Create a neural network classifier model\n",
    "mlp = MLPClassifier(max_iter=500, solver='adam', early_stopping=False)\n",
    "\n",
    "# Create a GridSearchCV object for the neural network classifier\n",
    "mlp_grid = GridSearchCV(mlp, params, scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "mlp_grid.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_mlp_params = mlp_grid.best_params_\n",
    "best_mlp_model = mlp_grid.best_estimator_\n",
    "\n",
    "print(f'Best NN parameters: {best_mlp_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_trainY_pred = best_mlp_model.predict(trainX_fully_preprocessed)\n",
    "neural_network_testY_pred = best_mlp_model.predict(testX_fully_preprocessed)\n",
    "\n",
    "print(\"TRAIN DATA:\")\n",
    "print_classification_metrics(trainY_binary, neural_network_trainY_pred)\n",
    "print(\"\\nTEST DATA:\")\n",
    "print_classification_metrics(testY_binary, neural_network_testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cost function trajectory over iterations\n",
    "plt.plot(best_mlp_model.loss_curve_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost Function Trajectory Over Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df09e9",
   "metadata": {},
   "source": [
    "Compare results of all classifications only for optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin regression\n",
    "print('lin reg lasso')\n",
    "# print_classification_metrics(testY_binary, lasso_testY_pred_binary)\n",
    "print('')\n",
    "print('lin reg ridge')\n",
    "# print_classification_metrics(testY_binary, ridge_testY_pred_binary)\n",
    "print('')\n",
    "# log regression\n",
    "print('log reg')\n",
    "# print_classification_metrics(testY_binary, logistic_testY_pred)\n",
    "print('')\n",
    "# svm\n",
    "print('svm')\n",
    "# print_classification_metrics(testY_binary, svm_testY_pred)\n",
    "print('')\n",
    "# nn\n",
    "print('neural network')\n",
    "# print_classification_metrics(testY_binary, neural_network_testY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ccbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(model, testX, testY, threshold=0.5):\n",
    "    '''\n",
    "    Evaluates a binary classification model on the test set\n",
    "    Returns a dictionary with the evaluation metrics\n",
    "    '''\n",
    "    predY = model.predict(testX) > threshold\n",
    "    \n",
    "    acc = accuracy_score(testY, predY)\n",
    "    prec = precision_score(testY, predY)\n",
    "    rec = recall_score(testY, predY)\n",
    "    f1 = f1_score(testY, predY)\n",
    "    roc_auc = roc_auc_score(testY, predY)\n",
    "    \n",
    "    return {'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC Score': roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c67319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Evaluation metrics dictionary for each model\n",
    "lasso_metrics = evaluate_classification_model(best_lasso_model, testX_fully_preprocessed, testY_binary)\n",
    "ridge_metrics = evaluate_classification_model(best_ridge_model, testX_fully_preprocessed, testY_binary)\n",
    "logistic_metrics = evaluate_classification_model(best_logistic_model, testX_fully_preprocessed, testY_binary)\n",
    "svm_metrics = evaluate_classification_model(best_svm_model, testX_fully_preprocessed, testY_binary)\n",
    "nn_metrics = evaluate_classification_model(best_mlp_model, testX_fully_preprocessed, testY_binary)\n",
    "\n",
    "# Create a pandas DataFrame for the evaluation metrics\n",
    "results = pd.DataFrame({'Model': ['Lasso Regression', 'Ridge Regression', 'Logistic Regression', 'SVM', 'Neural Network'],\n",
    "                   'Accuracy': [lasso_metrics['Accuracy'], ridge_metrics['Accuracy'], logistic_metrics['Accuracy'], svm_metrics['Accuracy'], nn_metrics['Accuracy']],\n",
    "                   'Precision': [lasso_metrics['Precision'], ridge_metrics['Precision'], logistic_metrics['Precision'], svm_metrics['Precision'], nn_metrics['Precision']],\n",
    "                   'Recall': [lasso_metrics['Recall'], ridge_metrics['Recall'], logistic_metrics['Recall'], svm_metrics['Recall'], nn_metrics['Recall']],\n",
    "                   'F1 Score': [lasso_metrics['F1 Score'], ridge_metrics['F1 Score'], logistic_metrics['F1 Score'], svm_metrics['F1 Score'], nn_metrics['F1 Score']],\n",
    "                   'ROC AUC Score': [lasso_metrics['ROC AUC Score'], ridge_metrics['ROC AUC Score'], logistic_metrics['ROC AUC Score'], svm_metrics['ROC AUC Score'], nn_metrics['ROC AUC Score']]})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f172dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Define the models you want to evaluate\n",
    "models = [('lin reg lasso', best_lasso_model),\n",
    "          ('lin reg ridge', best_ridge_model),\n",
    "          ('log reg', best_logistic_model),\n",
    "          ('svm', best_svm_model),\n",
    "          ('neural network', best_mlp_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lasso = confusion_matrix(testY_binary,lasso_testY_pred_binary)\n",
    "cm_ridge = confusion_matrix(testY_binary,ridge_testY_pred_binary)\n",
    "cm_log = confusion_matrix(testY_binary,logistic_testY_pred)\n",
    "cm_svm = confusion_matrix(testY_binary,svm_testY_pred)\n",
    "cm_nn = confusion_matrix(testY_binary,neural_network_testY_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_lasso.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_lasso.flatten()/np.sum(cm_lasso)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_lasso, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (6,4))\n",
    "fig.suptitle('All confusion matrices')\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_ridge.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_ridge.flatten()/np.sum(cm_ridge)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_ridge, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.suptitle('All confusion matrices')\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_log.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_log.flatten()/np.sum(cm_log)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_log, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.suptitle('All confusion matrices')\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_svm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_svm.flatten()/np.sum(cm_svm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_svm, annot=labels, fmt=\"\", cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.suptitle('All confusion matrices')\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm_nn.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm_nn.flatten()/np.sum(cm_nn)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm_nn, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e89384",
   "metadata": {},
   "source": [
    "# from here old code starts which does not follow our current procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ea20e",
   "metadata": {},
   "source": [
    "### SVM (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# train a SVM model using library\n",
    "classifier = SVC(kernel='rbf',random_state=1,C=1,gamma='auto')\n",
    "classifier.fit(trainX_fully_preprocessed,trainY)\n",
    "\n",
    "# perform prediction on x_test data\n",
    "y_pred = classifier.predict(testX_fully_preprocessed)\n",
    "\n",
    "cm = confusion_matrix(testY,y_pred)\n",
    "print(cm)\n",
    "accuracy = float(cm.diagonal().sum())/len(testY)\n",
    "print('model accuracy is:',accuracy*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703488c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the binary data to see whether the prediction is more easibly possible\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# train a SVM model using library\n",
    "classifier = SVC(kernel='rbf',random_state=1,C=1,gamma='auto')\n",
    "classifier.fit(trainX_fully_preprocessed,trainY_binary)\n",
    "\n",
    "# perform prediction on x_test data\n",
    "y_pred_binary = classifier.predict(testX_fully_preprocessed)\n",
    "\n",
    "cm = confusion_matrix(testY_binary,y_pred_binary)\n",
    "print(cm)\n",
    "accuracy = float(cm.diagonal().sum())/len(testY)\n",
    "print('model accuracy is:',accuracy*100,'%')\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print_classification_metrics(testY_binary, y_pred_binary)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cef0f",
   "metadata": {},
   "source": [
    "## Neural network from class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0506531",
   "metadata": {},
   "source": [
    "Define activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    \"\"\"\n",
    "    computes the gradient of the sigmoid function\n",
    "    \"\"\"\n",
    "    sigmoid = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    return sigmoid *(1-sigmoid) \n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    return the sigmoid of z\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1/ (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf8d3f",
   "metadata": {},
   "source": [
    "Define cost function\n",
    "\n",
    "Inputs for cost function:\n",
    "nn_params\n",
    "input_layer_size\n",
    "hidden_layer_size\n",
    "num_labels\n",
    "X\n",
    "y\n",
    "Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb21daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels, X, y,Lambda):\n",
    "    \"\"\"\n",
    "    nn_params contains the parameters unrolled into a vector\n",
    "    \n",
    "    compute the cost and gradient of the neural network\n",
    "    \"\"\"\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2\n",
    "    Theta1 = nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
    "    Theta2 = nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    J=0\n",
    "    X = np.hstack((np.ones((m,1)),X))\n",
    "    y10 = np.zeros((m,num_labels))\n",
    "    \n",
    "    a1 = sigmoid(X @ Theta1.T)\n",
    "    a1 = np.hstack((np.ones((m,1)), a1)) # hidden layer\n",
    "    a2 = sigmoid(a1 @ Theta2.T) # output layer\n",
    "    \n",
    "    for i in range(1,num_labels+1):\n",
    "        # y10[:,i-1][:,np.newaxis] = np.where(y==i,1,0)\n",
    "        y10[:, i-1] = np.where(y==i, 1, 0)\n",
    "    for j in range(num_labels):\n",
    "        J = J + sum(-y10[:,j] * np.log(a2[:,j]) - (1-y10[:,j])*np.log(1-a2[:,j]))\n",
    "    \n",
    "    cost = 1/m* J\n",
    "    reg_J = cost + Lambda/(2*m) * (np.sum(Theta1[:,1:]**2) + np.sum(Theta2[:,1:]**2))\n",
    "    \n",
    "    # Implement the backpropagation algorithm to compute the gradients\n",
    "    \n",
    "    grad1 = np.zeros((Theta1.shape))\n",
    "    grad2 = np.zeros((Theta2.shape))\n",
    "    \n",
    "    for i in range(m):\n",
    "        xi= X[i,:] # 1 X 401\n",
    "        a1i = a1[i,:] # 1 X 26\n",
    "        a2i =a2[i,:] # 1 X 10\n",
    "        d2 = a2i - y10[i,:]\n",
    "        d1 = Theta2.T @ d2.T * sigmoidGradient(np.hstack((1,xi @ Theta1.T)))\n",
    "        grad1= grad1 + d1[1:][:,np.newaxis] @ xi[:,np.newaxis].T\n",
    "        grad2 = grad2 + d2.T[:,np.newaxis] @ a1i[:,np.newaxis].T\n",
    "        \n",
    "    grad1 = 1/m * grad1\n",
    "    grad2 = 1/m*grad2\n",
    "    \n",
    "    grad1_reg = grad1 + (Lambda/m) * np.hstack((np.zeros((Theta1.shape[0],1)),Theta1[:,1:]))\n",
    "    grad2_reg = grad2 + (Lambda/m) * np.hstack((np.zeros((Theta2.shape[0],1)),Theta2[:,1:]))\n",
    "    \n",
    "    return cost, grad1, grad2, reg_J, grad1_reg, grad2_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa64d422",
   "metadata": {},
   "source": [
    "Random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out):\n",
    "    \"\"\"\n",
    "    randomly initializes the weights of a layer with L_in incoming connections and L_out outgoing connections.\n",
    "    \"\"\"\n",
    "    \n",
    "    epi = (6**1/2) / (L_in + L_out)**1/2\n",
    "    \n",
    "    W = np.random.rand(L_out,L_in +1) *(2*epi) -epi\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97089a12",
   "metadata": {},
   "source": [
    "Learning parameters using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentnn(X,y,initial_nn_params,alpha,num_iters,Lambda,input_layer_size, hidden_layer_size, num_labels):\n",
    "    \"\"\"\n",
    "    Take in numpy array X, y and theta and update theta by taking num_iters gradient steps\n",
    "    with learning rate of alpha\n",
    "    \n",
    "    return theta and the list of the cost of theta during each iteration\n",
    "    \"\"\"\n",
    "    Theta1 = initial_nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
    "    Theta2 = initial_nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
    "    \n",
    "    m=len(y)\n",
    "    J_history =[]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        nn_params = np.append(Theta1.flatten(),Theta2.flatten())\n",
    "        cost, grad1, grad2 = nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels,X, y,Lambda)[3:]\n",
    "        Theta1 = Theta1 - (alpha * grad1)\n",
    "        Theta2 = Theta2 - (alpha * grad2)\n",
    "        J_history.append(cost)\n",
    "    \n",
    "    nn_paramsFinal = np.append(Theta1.flatten(),Theta2.flatten())\n",
    "    return nn_paramsFinal , J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc964e7a",
   "metadata": {},
   "source": [
    "Now we need to define the parameters for our neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = 34\n",
    "hidden_layer_size = 50\n",
    "num_labels = 2\n",
    "num_labels_binary = 2\n",
    "alpha=0.001 #learning rate\n",
    "num_iters=1000\n",
    "Lambda=0.1\n",
    "\n",
    "# X = trainX_fully_preprocessed\n",
    "# y = trainY\n",
    "# y_binary = trainY_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "\n",
    "initial_nn_params = np.append(initial_Theta1.flatten(),initial_Theta2.flatten())\n",
    "\n",
    "nnTheta, nnJ_history = gradientDescentnn(trainX_fully_preprocessed,trainY_binary,initial_nn_params,alpha,num_iters,Lambda,input_layer_size, hidden_layer_size, num_labels)\n",
    "\n",
    "Theta1 = nnTheta[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
    "Theta2 = nnTheta[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cost function evolution during training.\n",
    "#In order to say learning has finished, the cost function has to converge to a flat rate\n",
    "plt.plot(nnJ_history)  #\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"$J(\\Theta)$\")\n",
    "plt.title(\"Cost function using Gradient Descent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81517cda",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    \"\"\"\n",
    "    Predict the label of an input given a trained neural network\n",
    "    \"\"\"\n",
    "    m= X.shape[0]\n",
    "    #Add a column of ones\n",
    "  \n",
    "    X = np.append(np.ones((m,1)),X, axis=1)\n",
    "    \n",
    "    #Compute the output of the hidden layer (with sigmoid activation functions)\n",
    "    z1=np.dot(X, Theta1.T)\n",
    "    a1=sigmoid(z1)\n",
    "    \n",
    "    #Add a column of ones\n",
    "    a1 = np.append(np.ones((m,1)),a1, axis=1)\n",
    "    \n",
    "    #Compute the output of the output layer (with sigmoid activation functions)\n",
    "    z2=np.dot(a1, Theta2.T)\n",
    "    a2=sigmoid(z2)\n",
    "    \n",
    "    return np.argmax(a2,axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f07d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = predict(Theta1, Theta2, testX_fully_preprocessed)\n",
    "\n",
    "m = len(testY)\n",
    "pred3 = pred3.reshape(m,1)\n",
    "trainY_array = testY_binary.values.reshape(m,1)\n",
    "\n",
    "print(\"Training Set Accuracy:\",sum(pred3==trainY_array)/m*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04a647",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5013383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# important \n",
    "# trainX_fully_preprocessed\n",
    "# testX_fully_preprocessed\n",
    "\n",
    "# trainY\n",
    "# testY\n",
    "\n",
    "# trainY_binary\n",
    "# testY_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(34, 10), max_iter = 2000, random_state=1)\n",
    "\n",
    "clf.fit(trainX_fully_preprocessed,trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = clf.predict(trainX_fully_preprocessed)\n",
    "\n",
    "m = len(trainY)\n",
    "nn_pred = nn_pred.reshape(m,1)\n",
    "trainY_array = trainY.values.reshape(m,1)\n",
    "\n",
    "print(\"Training Set Accuracy:\",sum(nn_pred==trainY_array)/m*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cacfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred_test = clf.predict(testX_fully_preprocessed)\n",
    "\n",
    "m_test = len(testY)\n",
    "nn_pred_test = nn_pred_test.reshape(m_test,1)\n",
    "trainY_array = testY.values.reshape(m_test,1)\n",
    "\n",
    "print(\"Training Set Accuracy:\",sum(nn_pred_test==trainY_array)/m_test*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b13678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(3, 1, 1) # row 1, col 2 index 1\n",
    "# plt.plot(nn_pred_test)\n",
    "# plt.subplot(3, 1, 2) # row 1, col 2 index 1\n",
    "# plt.plot(testY_array)\n",
    "# plt.subplot(3, 1, 3) # row 1, col 2 index 1\n",
    "# plt.plot(nn_pred_test)\n",
    "# plt.plot(testY_array)\n",
    "cm = confusion_matrix(testY,nn_pred_test)\n",
    "print(cm)\n",
    "accuracy = float(cm.diagonal().sum())/len(testY)\n",
    "print('model accuracy is:',accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa40e9",
   "metadata": {},
   "source": [
    "### Binary classification (neural networks - sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_binary = MLPClassifier(solver='lbfgs', alpha=1e-6,hidden_layer_sizes=(34, 10), max_iter = 5000, random_state=1)\n",
    "\n",
    "clf_binary.fit(trainX_fully_preprocessed,trainY_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee33370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_pred_binary = clf_binary.predict(trainX_fully_preprocessed)\n",
    "# m_binary = len(trainY_binary)\n",
    "# nn_pred_binary = nn_pred_binary.reshape(m_binary,1)\n",
    "# trainY_array_binary = trainY_binary.values.reshape(m_binary,1)\n",
    "# print(\"Training Set Accuracy:\",sum(nn_pred_binary==trainY_array_binary)/m_binary*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50eac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred_binary_test = clf_binary.predict(testX_fully_preprocessed)\n",
    "m_binary_test = len(testY_binary)\n",
    "nn_pred_binary_test = nn_pred_binary_test.reshape(m_binary_test,1)\n",
    "testY_array= testY_binary.values.reshape(m_binary_test,1)\n",
    "\n",
    "print(\"Training Set Accuracy:\",sum(nn_pred_binary_test==testY_array)/m_binary_test*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d17d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(testY_binary,nn_pred_binary_test)\n",
    "print(cm)\n",
    "accuracy = float(cm.diagonal().sum())/len(testY)\n",
    "print('model accuracy is:',accuracy*100,'%')\n",
    "\n",
    "print_classification_metrics(testY_binary, nn_pred_binary_test)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498302e",
   "metadata": {},
   "source": [
    "Neural network - clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural  model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_reg.fit(trainX_fully_preprocessed, trainY_binary)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "testY_pred = linear_reg.predict(testX_fully_preprocessed)\n",
    "\n",
    "# Since linear regression returns continuous values, we need to convert the predictions into binary classification\n",
    "testY_pred_binary = (testY_pred >= 0.5).astype(int)\n",
    "\n",
    "# Calculate and print the evaluation and classification metrics\n",
    "print_evaluation_metrics(testY_binary, testY_pred)\n",
    "print_classification_metrics(testY_binary, testY_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab35bfae",
   "metadata": {},
   "source": [
    "## use this for visualizing the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44cb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
